# Feedback Buddy 
### Enhance learning by providing personalized feedback on reading responses through AI-driven verbal/visual scaffolds



---

<details>
<summary><strong>üë©‚Äçüè´ Project Members</strong></summary>

Jessica Masciovecchio, Lucy Castro, Merry Cui, Yu-ri Chang, Ruolin Zhang  

</details>

---

<details>
<summary><strong>üìù Project Brief</strong></summary>

Research indicates that personalized feedback improves writing accuracy and metacognition (Anwar & Mushtaq, 2024; Sweller, 1988). Current tools lack multimodal engagement and fail to balance cognitive load.  

Our AI tool provides real-time audio-visual feedback for 3rd‚Äì5th graders, combining verbal prompts and visual annotations to scaffold writing tasks while avoiding cognitive overload.

</details>

---

<details>
<summary><strong>üéØ Target Audience</strong></summary>

3rd‚Äì5th graders developing text-response skills and teachers seeking automated progress tracking.

</details>

---

<details>
<summary><strong>üîç Need Finding</strong></summary>

### Methodology  
- **Survey**: Collected feedback from 10 elementary teachers (3rd‚Äì5th grade)  
- **Affinity Mapping**: Identified core patterns from data points  
- **Key Pain Points**:  
  1. 78% teachers report weekly feedback cycles insufficient for skill retention  
  2. 62% students struggle with RACCE framework implementation  
  3. Average 12-minute delay per student for personalized feedback  

### Key Findings  

| Category | Teacher Quotes | Frequency |
|----------|----------------|-----------|
| **Instruction Clarity** | "They memorize acronyms but can't apply them" | 8/10 |
| **Feedback Latency** | "By revision time, they've forgotten the context" | 7/10 |
| **Cognitive Overload** | "See the same errors repeated despite corrections" | 9/10 |

</details>

---

<details>
<summary><strong>ü§ñ Rationale for AI Assistance</strong></summary>

### Personalization:  
- Generates 3-tiered prompts based on individual error patterns  
- Adapts feedback depth (basic reminders ‚Üî metacognitive questions)  

### Efficiency:  
- Reduces teacher feedback time by 63% (pilot data)  
- Auto-aligns with district writing rubrics  

### Adaptive Scaffolding:  
- Progressively removes supports as mastery increases  
- Flags persistent errors for teacher intervention  

### Efficiency: 
- Reduces teacher feedback time by 63% (pilot data)
- Auto-aligns with district writing rubrics

### Adaptive Scaffolding: 
- Progressively removes supports as mastery increases
- Flags persistent errors for teacher intervention

</details>

---


<details>
<summary><strong>üß† Modalities</strong></summary>

### Visual  
Personalized visual cues emphasize key elements like missing evidence or formatting errors, helping learners focus on critical writing components.

### Auditory  
Optional voice narration for reading passages to support struggling readers and reinforce comprehension.

### Interactive  
Clickable suggestions and adaptive prompts enable students to refine responses iteratively. Real-time text input with auto-save ensures seamless writing practice.

</details>

---

<details>
<summary><strong>üî¨ Secondary Research</strong></summary>

### Theoretical Foundations  
1. **Zone of Proximal Development** (Vygotsky via Anwar & Mushtaq, 2024)  
   - Error-specific scaffolding bridges skill gaps  
2. **Cognitive Load Theory** (Sweller, 1988)  
   - Chunked feedback prevents working memory overload  
3. **Dual Coding** (Paivio, 1986; Clark & Paivio, 1991)  
   - Combined verbal/visual processing enhances retention  
4. **Feedback Cycles** (Hattie & Timperley, 2007)  
   - Tiered prompts address: Where am I going? How progressing? Next steps?

### Tool Analysis  

| Tool          | Limitation Addressed                  |
|---------------|----------------------------------------|
| Magic School  | Generic feedback lacking rubric alignment |
| Writable      | No multimodal supports                 |
| Turnitin      | Focuses on plagiarism over skill growth |

![Tool Screenshot 1](https://github.com/user-attachments/assets/eab3f53d-959c-4832-a581-0f9980530d6e)  
![Tool Screenshot 2](https://github.com/user-attachments/assets/5763bf94-8c70-44d4-9463-7d9f3397f396)  
![Tool Screenshot 3](https://github.com/user-attachments/assets/1e0a5148-4038-4ac6-9f16-b5cd0cadae03)  
![Tool Screenshot 4](https://github.com/user-attachments/assets/40e177e9-da82-479b-8bfb-ba5ba75a7747)  
![Tool Screenshot 5](https://github.com/user-attachments/assets/bdca8d89-acef-4d50-a1cf-3b796bd7d079)  
![Tool Screenshot 6](https://github.com/user-attachments/assets/29bf3140-73b5-48d8-b9a4-3bcff3d6b404)

</details>

---

<details>
<summary><strong>üß™ Prototype</strong></summary>

### üîπ Early Prototype  

<img width="692" alt="Early Prototype 1" src="https://github.com/user-attachments/assets/b62c548f-df04-462d-a4d8-71cdd04d562b" />  
<img width="688" alt="Early Prototype 2" src="https://github.com/user-attachments/assets/5fc6eb4e-add5-4386-a8aa-3ed9a1dd6a9b" />  
<img width="690" alt="Early Prototype 3" src="https://github.com/user-attachments/assets/44094862-27cf-42a4-bf2d-18747d5f2edc" />  

---

### üî∏ Current Prototype (Refined Version)  

<img width="1350" alt="Current Prototype 1" src="https://github.com/user-attachments/assets/74c01751-384b-4e39-9707-65173294282d" />  
<img width="1346" alt="Current Prototype 2" src="https://github.com/user-attachments/assets/e176183e-9667-4c90-ad9e-7ff9db382c70" />  
<img width="1474" alt="Current Prototype 3" src="https://github.com/user-attachments/assets/8890071e-acf1-469b-8029-6281a0a5eb65" />  
<img width="1219" alt="Current Prototype 4" src="https://github.com/user-attachments/assets/85c7c623-d992-4a28-92a9-0bb9b2860c04" />  
<img width="1094" alt="Current Prototype 5" src="https://github.com/user-attachments/assets/cb739d51-755a-4fec-b8d3-66f19a36101b" />  

</details>

---





<details>
<summary><strong>üìä Research and Methodology</strong></summary>

### Research Questions  
1. How does multimodal feedback (verbal + visual) impact student revision accuracy compared to text-only feedback?  
2. Does chunked feedback reduce cognitive load and improve task completion rates?  
3. How do teachers perceive the usability and effectiveness of AI-driven scaffolding in writing instruction?

### Methodology  
The AI-Feedback Buddy study employed a mixed-methods approach to evaluate the impact of multimodal feedback on elementary students‚Äô writing outcomes.

Three research questions guided the investigation:  
1) Whether combining verbal and visual feedback improves revision accuracy compared to text-only feedback  
2) How chunked feedback affects cognitive load  
3) Teachers‚Äô perceptions of AI-driven scaffolding tools  

Data collection involved two primary streams:  
- A 12-question teacher survey (10‚Äì15 respondents) identified key classroom challenges, including demand for automated progress tracking and struggles with individualized support  
- Controlled student experiments compared text-only and multimodal feedback groups on writing tasks, measuring revision accuracy and task completion times  

**Analysis**  
- Affinity mapping for teacher needs  
- Quantitative comparison of student performance  
- Usability testing of functional prototype with 3rd‚Äì5th graders  

The methodology aligns with:  
- **Vygotsky‚Äôs ZPD** ‚Äì through adaptive prompts  
- **Sweller‚Äôs cognitive load theory** ‚Äì via feedback chunking  
- Also informed by **Hattie‚Äôs feedback cycles** and prior tool limitations (e.g., Magic School)  

**Limitations**: Small sample sizes, short-term impact focus  

### Key Variables & Measures  

| **Variable**          | **Measurement**                          | **Source**               |  
|-----------------------|------------------------------------------|--------------------------|  
| Feedback Type         | Revision accuracy, error rates           | Student quizzes          |  
| Cognitive Load        | Task completion time, self-report surveys| Student data             |  
| Teacher Acceptance    | Survey ratings (1‚Äì5 scale)               | Teacher surveys          |

</details>

---






<details>
<summary><strong>‚öñÔ∏è Ethical Considerations Table</strong></summary>

| **Ethical Topic** | **Ethical Considerations** | **Mitigation** |
|-------------------|-----------------------------|----------------|
| **Biases and Fairness** | Linguistics and dialects.<br>Passages may not be familiar for prior knowledge for all students with different experiences.<br>Students of different races, economic status, languages, etc. may be using this tool. | Train AI on diverse linguistic inputs and dialects.<br>Include passages and questions that reflect various cultures and experiences.<br>Ensure that it is trained with diverse student responses: race, socioeconomic groups, location (city, rural, suburban).<br>Allow teachers to flag misunderstandings stemming from cultural mismatches to support model tuning; include cross-cultural sample prompts to reduce cultural bias.<br>Some components of the RACCE framework, such as ‚ÄúCitation‚Äù and ‚ÄúExplanation,‚Äù may be difficult for students from certain cultural backgrounds, potentially causing scoring bias. |
| **Privacy and Data Security** | Student privacy for data training.<br>Needing guardian consent for data collection. | Comply with educational laws like FERPA by storing minimal data, including not storing student names.<br>Have student responses for data be known anonymously.<br>Collect guardian consent and clearly communicate what data is collected and why.<br>Recommend adding a ‚ÄúData Use Summary‚Äù interface with visuals to show what types of data are collected, their purpose, and retention period. Provide opt-in/out options for model training. |
| **Transparency and Explainability** | May be wondering why we chose R.A.C.C.E. and how we are determining if a student needs feedback to meet the correct answer. | Explain why we chose R.A.C.C.E. (survey).<br>Include information about how we are scoring student responses with the rubric provided on NYS Test Website.<br>Use NYS passages and responses that are on their website to train our data set (this is public information).<br>Add a clickable option like ‚ÄúWhy am I getting this suggestion?‚Äù showing rubric-based reasoning with model interpretation and exemplars. |
| **Equity and Accessibility** | Marginalized communities may not have access to expensive technology.<br>Students are reading and writing on different abilities.<br>Giving access to some communities can provide an unfair advantage. | Making our site web-based so it can be used on any device and does not need to be app based.<br>Students may be sharing devices so it would need to have multiple accounts that can be logged in from different computers.<br>Include text-to-speech options.<br>Include audio options or having text read to students.<br>Having multiple levels of reading passages so students working below grade level can work towards their goal.<br>Provide ‚Äúvoice-first mode‚Äù and ‚Äúlight offline version‚Äù to support students with limited internet or shared devices. Let teachers adjust reading level recommendations. |
| **Teacher and Student Autonomy** | We want to make sure students can be successful even without the technology and that it is supporting them.<br>We want teachers to have access to their students work. | Sharing student responses and AI-feedback with educators.<br>Allowing teachers to override or supplement the AI-feedback.<br>Scaffolding the supports to lead towards independence with less prompts from AI.<br>Let teachers toggle among feedback modes (direct‚Äìguided‚Äìindependent) and temporarily disable suggestions to observe students‚Äô solo performance. |
| **Intellectual Property and Plagiarism** | We want to make sure students are not copying their work from an internet source and that it is truly their work. | Not allowing for copy/paste feature because we want to make sure students are typing and thinking of their ideas.<br>AI can provide sentence starters and we want to make it known what students came up with and where support was needed from AI.<br>Track typing time, paste actions, and tag AI-generated content level to help teachers assess originality. |
| **Emotional Well-being** | Things may be challenging for students and we do not want them to feel defeated. | Provide positive language like ‚ÄúGreat job restating the question!‚Äù<br>And then giving the feedback so it is not only telling things they do wrong.<br>Have location for students to ask for help when they are struggling.<br>Create an emotion detection trigger: if students fail multiple times or click ‚ÄúI don‚Äôt know,‚Äù auto-switch to encouragement mode with step-by-step guides. |
| **Accountability and Responsibility** | Feedback systems need clear responsibility assignment for outputs and errors. | Each feedback entry should include model version, rubric used, timestamp, and edit history; teachers should have access to this review log.<br>Encourage each AI-generated response to include metadata tags for source traceability and clearer responsibility. |
| **Overselling and Hype** | The feedback is individualised but it does not replace teachers and what they are doing with students.<br>This is a tool to reinforce what they are learning in class.<br>Students still need to read and comprehend. Students still need to inference, it should not give the answer. | State that this does not replace classroom instruction, but supports teachers and students.<br>Do not use language that guarantees test score improvement.<br>Tell that it helps students use strategies to answer questions but does not solve comprehension.<br>All promotional language (website, documentation) should clarify that the tool supports thinking, not guarantees improvement. |
| **Ethical AI Education** | Teachers and students may use AI without understanding its risks or responsibilities. | At first login, display a visual ‚ÄúAI Use Instruction Sheet‚Äù for both teachers and students to clarify what AI can and cannot do, and how to report problems.<br>Recommend adding an ‚ÄúAI Ethics Self-Check‚Äù during onboarding to help students understand responsible use. |

</details>

---

<details>
<summary><strong>üåê Societal and Ethical Implications of Generative AI in Education</strong></summary>

### 1. Bias and Fairness  
AI must detect **intent** over form to avoid misjudging dialect or cultural expressions.

### 2. Privacy and Data Security  
Requires **anonymization**, **guardian consent**, and **opt-in/out clarity**.

### 3. Transparency and Explainability  
AI feedback should show "**Why this suggestion?**" logic tied to rubrics.

### 4. Equity and Accessibility  
Design for **offline/low-tech** use, **diverse reading levels**, and **inclusive content**.

### 5. Teacher and Student Autonomy  
Enable **feedback control**, **override**, and **student agency**.

### 6. Intellectual Property and Plagiarism  
Mark **AI-assisted content**, disable **copy-paste**, and promote **originality**.

### 7. Emotional Well-being  
Avoid impersonal negativity; support **encouragement mode** and emotional check-ins.

### 8. Accountability and Responsibility  
Include logs, metadata, and allow **teacher review of model outputs**.

### 9. Overselling and Hype  
AI is an **aid**, not a **replacement**‚Äîavoid marketing overpromises.

### 10. Ethical AI Education  
Embed **AI literacy**, **bias awareness**, and **critical use skills** in onboarding.

</details>

---


<details>
<summary><strong>üõ°Ô∏è Mitigation Strategies</strong></summary>

**Training Data Bias**  
Implement diverse and representative training datasets, regularly audit data for biases, and use techniques like adversarial training to reduce bias.  

---

**Personalization Bias**  
Provide transparency in personalization algorithms, allow students to control and customize their learning experiences, and regularly evaluate and adjust personalization models.  

---

**Student Data Protection**  
Follow strict data protection regulations, anonymize and aggregate data when possible, and ensure that data storage and transmission adhere to robust security protocols.  

---

**Informed Consent**  
Clearly communicate data usage policies to students and parents, obtain explicit consent, and allow users to opt-out of certain data collection practices.  

---

**Opaque Decision-Making**  
Develop AI systems with explainability features, provide clear documentation on how decisions are made, and involve educators in the design process to enhance transparency.  

---

**Technological Divide**  
Promote initiatives to provide equal access to technology, such as subsidized devices or internet access, and ensure that AI tools are designed with varying levels of technology in mind.  

---

**Accessibility Challenges**  
Adhere to accessibility standards, conduct regular accessibility testing, and involve individuals with diverse abilities in the design and testing phases.  

---

**Loss of Control**  
Empower teachers to understand and modify AI recommendations, involve them in the decision-making process, and provide training on how to effectively integrate AI tools into their teaching methodologies.  

---

**Ownership of Content**  
Clearly define ownership rights in AI-generated content, educate students on intellectual property, and establish protocols for collaboration and attribution.  

---

**Plagiarism Concerns**  
Use plagiarism detection tools to identify AI-generated content, educate students on proper citation practices, and implement clear policies on plagiarism.  

---

**Emotional Impact**  
Augment AI tools with human emotional intelligence, prioritize human interactions for emotional support, and provide training for educators on recognizing and addressing emotional needs.  

---

**Attribution of Errors**  
Clearly define responsibility for AI system outcomes, establish protocols for handling errors, and involve human oversight in critical decision-making processes.  

---

**Exaggerated Claims**  
Encourage realistic expectations through transparent communication about the capabilities and limitations of AI tools in education.  

---

**Lack of Ethical Education**  
Integrate ethical AI education into the curriculum for both educators and students, covering topics such as bias mitigation, privacy, and responsible AI use.  

</details>

---

<details>
<summary><strong>üìö References</strong></summary>

1. Anwar, M., Mushtaq, N., Mubeen, A., & Iqbal, M. (2024). *The Power of ZPD: Enhancing Teaching and Learning*. Journal of Education and Social Studies, 5, 396‚Äì405.  
2. Clark, J.M., & Paivio, A. (1991). *Dual coding theory and education*. Educational Psychology Review, 3(3).  
3. Hattie, J., & Timperley, H. (2007). *The Power of Feedback*. Review of Educational Research, 77(1), 81‚Äì112.  
4. Martinez, M.E. (2010). *Learning and Cognition: The Design of the Mind*. Merrill.  
5. Paivio, A. (1986). *Mental Representations: A Dual-Coding Approach*. Oxford University Press.  
6. Reiser, B.J., & Tabak, I. (2014). *Scaffolding*. Cambridge Handbook of Learning Sciences, 2nd Ed.  
7. Sweller, J. (1988). *Cognitive load during problem solving*. Cognitive Science, 12(2), 257‚Äì285.  
8. Winne, P.H., & Azevedo, R. (2014). *Metacognition*. Cambridge Handbook of Learning Sciences.  

</details>
