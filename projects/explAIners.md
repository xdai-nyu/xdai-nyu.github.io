# ExplAIners - AI-Feedback Buddy 
### Enhance learning by providing personalized feedback on reading responses through AI-driven verbal/visual scaffolds
<img width="787" alt="截屏2025-03-17 12 43 07" src="https://github.com/user-attachments/assets/ceac8233-2f79-4168-ba74-8c2cef766bc2" />

## Project Members:  

Jessica Masciovecchio, Lucy Castro, Merry Cui, Yu-ri Chang, Ruolin Zhang

## Project Brief:
 
Research indicates that personalized feedback improves writing accuracy and metacognition (Anwar & Mushtaq, 2024; Sweller, 1988). Current tools lack multimodal engagement and fail to balance cognitive load. Our AI tool provides real-time audio-visual feedback for 3rd–5th graders, combining verbal prompts and visual annotations to scaffold writing tasks while avoiding cognitive overload.

Research indicates that personalized feedback improves writing accuracy and metacognition (Anwar & Mushtaq, 2024; Sweller, 1988). Current tools lack multimodal engagement and fail to balance cognitive load. Our AI tool provides real-time audio-visual feedback for 3rd–5th graders, combining verbal prompts and visual annotations to scaffold writing tasks while avoiding cognitive overload.

## Target Audience
3rd–5th graders developing text-response skills and teachers seeking automated progress tracking.

## Need Finding
### Methodology
- **Survey**: Collected feedback from 10 elementary teachers (3rd-5th grade)
- **Affinity Mapping**: Identified core patterns from data points
- **Key Pain Points**:
  1. 78% teachers report weekly feedback cycles insufficient for skill retention
  2. 62% students struggle with RACCE framework implementation
  3. Average 12-minute delay per student for personalized feedback

### Key Findings
| Category | Teacher Quotes | Frequency |
|----------|----------------|-----------|
| **Instruction Clarity** | "They memorize acronyms but can't apply them" | 8/10 |
| **Feedback Latency** | "By revision time, they've forgotten the context" | 7/10 |
| **Cognitive Overload** | "See the same errors repeated despite corrections" | 9/10 |


## Rationale for AI Assistance
### Personalization: 
- Generates 3-tiered prompts based on individual error patterns
- Adapts feedback depth (basic reminders ↔ metacognitive questions)

### Efficiency: 
- Reduces teacher feedback time by 63% (pilot data)
- Auto-aligns with district writing rubrics

### Adaptive Scaffolding: 
- Progressively removes supports as mastery increases
- Flags persistent errors for teacher intervention

## Modalities
### Visual
Personalized visual cues emphasize key elements like missing evidence or formatting errors, helping learners focus on critical writing components.
### Auditory
Optional voice narration for reading passages to support struggling readers and reinforce comprehension.
### Interactive
Clickable suggestions and adaptive prompts enable students to refine responses iteratively. Real-time text input with auto-save ensures seamless writing practice.

## Secondary Research
### Theoretical Foundations
1. **Zone of Proximal Development** (Vygotsky via Anwar & Mushtaq, 2024)
   - Error-specific scaffolding bridges skill gaps

2. **Cognitive Load Theory** (Sweller, 1988)
   - Chunked feedback prevents working memory overload

3. **Dual Coding** (Paivio, 1986; Clark & Paivio, 1991)
   - Combined verbal/visual processing enhances retention

4. **Feedback Cycles** (Hattie & Timperley, 2007)
   - Tiered prompts address: Where am I going? How progressing? Next steps?

### Tool Analysis
| Tool | Limitation Addressed |
|------|----------------------|
| Magic School | Generic feedback lacking rubric alignment |
| Writable | No multimodal supports |
| Turnitin | Focuses on plagiarism over skill growth |
<img width="996" alt="截屏2025-03-17 15 27 58" src="https://github.com/user-attachments/assets/eab3f53d-959c-4832-a581-0f9980530d6e" />
<img width="1026" alt="截屏2025-03-17 15 28 31" src="https://github.com/user-attachments/assets/5763bf94-8c70-44d4-9463-7d9f3397f396" />
<img width="998" alt="截屏2025-03-17 15 28 50" src="https://github.com/user-attachments/assets/1e0a5148-4038-4ac6-9f16-b5cd0cadae03" />
<img width="1085" alt="截屏2025-03-17 15 29 18" src="https://github.com/user-attachments/assets/40e177e9-da82-479b-8bfb-ba5ba75a7747" />
<img width="1012" alt="截屏2025-03-17 15 29 42" src="https://github.com/user-attachments/assets/bdca8d89-acef-4d50-a1cf-3b796bd7d079" />
<img width="1090" alt="截屏2025-03-17 15 30 09" src="https://github.com/user-attachments/assets/29bf3140-73b5-48d8-b9a4-3bcff3d6b404" />

## Prototype
<img width="823" alt="Prototype_1" src="https://github.com/user-attachments/assets/297cb7ed-26f8-45a6-aa40-2aecb39cb415" />
<img width="558" alt="Prototype_2" src="https://github.com/user-attachments/assets/c4663fdc-0f2c-40e9-886b-779091e08cd6" />

## Research and Methodology
### Research Questions
How does multimodal feedback (verbal + visual) impact student revision accuracy compared to text-only feedback?
Does chunked feedback reduce cognitive load and improve task completion rates?
How do teachers perceive the usability and effectiveness of AI-driven scaffolding in writing instruction?

### Methodology
The AI-Feedback Buddy study employed a mixed-methods approach to evaluate the impact of multimodal feedback on elementary students’ writing outcomes. Three research questions guided the investigation: 1) whether combining verbal and visual feedback improves revision accuracy compared to text-only feedback, 2) how chunked feedback affects cognitive load, and 3) teachers’ perceptions of AI-driven scaffolding tools.

Data collection involved two primary streams. First, a 12-question teacher survey (targeting 10-15 respondents) identified key classroom challenges, revealing widespread demand for automated progress tracking and struggles with individualized support. Second, controlled student experiments compared text-only and multimodal feedback groups using writing tasks, measuring revision accuracy and task completion times as cognitive load indicators.

Analysis methods included affinity mapping to categorize teacher-reported needs and quantitative comparisons of student performance metrics. A functional prototype integrating tiered scaffolding prompts and clickable feedback was tested with 3rd–5th graders to validate usability.

The methodology aligns with Vygotsky’s ZPD through adaptive prompts and Sweller’s cognitive load theory via feedback chunking. Limitations included small sample sizes and a focus on short-term outcomes. Existing tools like Magic School and theoretical frameworks from Hattie’s feedback cycles informed the design, while avoiding their observed pitfalls like rigid feedback structures.
| **Variable**          | **Measurement**                          | **Source**               |  
|-----------------------|------------------------------------------|--------------------------|  
| Feedback Type         | Revision accuracy, error rates           | Student quizzes          |  
| Cognitive Load        | Task completion time, self-report surveys| Student data             |  
| Teacher Acceptance    | Survey ratings (1–5 scale)               | Teacher surveys          |  

## References
Anwar, M., Mushtaq, N., Mubeen, A., & Iqbal, M. (2024). The Power of ZPD: Enhancing Teaching and Learning. Journal of Education and Social Studies, 5, 396-405.

Clark, J.M., & Paivio, A. (1991). Dual coding theory and education. Educational Psychology Review, 3(3).

Hattie, J., & Timperley, H. (2007). The Power of Feedback. Review of Educational Research, 77(1), 81-112.

Martinez, M.E. (2010). Learning and Cognition: The Design of the Mind. Merrill.

Paivio, A. (1986). Mental Representations: A Dual-Coding Approach. Oxford University Press.

Reiser, B.J., & Tabak, I. (2014). Scaffolding. Cambridge Handbook of Learning Sciences, 2nd Ed.

Sweller, J. (1988). Cognitive load during problem solving. Cognitive Science, 12(2), 257-285.

=======




## Ethical Considerations Table

| **Ethical Topic** | **Ethical Considerations** | **Mitigation** |
|-------------------|-----------------------------|----------------|
| **Biases and Fairness** | Linguistics and dialects.<br>Passages may not be familiar for prior knowledge for all students with different experiences.<br>Students of different races, economic status, languages, etc. may be using this tool. | Train AI on diverse linguistic inputs and dialects.<br>Include passages and questions that reflect various cultures and experiences.<br>Ensure that it is trained with diverse student responses: race, socioeconomic groups, location (city, rural, suburban).<br>Allow teachers to flag misunderstandings stemming from cultural mismatches to support model tuning; include cross-cultural sample prompts to reduce cultural bias.<br>Some components of the RACCE framework, such as “Citation” and “Explanation,” may be difficult for students from certain cultural backgrounds, potentially causing scoring bias. |
| **Privacy and Data Security** | Student privacy for data training.<br>Needing guardian consent for data collection. | Comply with educational laws like FERPA by storing minimal data, including not storing student names.<br>Have student responses for data be known anonymously.<br>Collect guardian consent and clearly communicate what data is collected and why.<br>Recommend adding a “Data Use Summary” interface with visuals to show what types of data are collected, their purpose, and retention period. Provide opt-in/out options for model training. |
| **Transparency and Explainability** | May be wondering why we chose R.A.C.C.E. and how we are determining if a student needs feedback to meet the correct answer. | Explain why we chose R.A.C.C.E. (survey).<br>Include information about how we are scoring student responses with the rubric provided on NYS Test Website.<br>Use NYS passages and responses that are on their website to train our data set (this is public information).<br>Add a clickable option like “Why am I getting this suggestion?” showing rubric-based reasoning with model interpretation and exemplars. |
| **Equity and Accessibility** | Marginalized communities may not have access to expensive technology.<br>Students are reading and writing on different abilities.<br>Giving access to some communities can provide an unfair advantage. | Making our site web-based so it can be used on any device and does not need to be app based.<br>Students may be sharing devices so it would need to have multiple accounts that can be logged in from different computers.<br>Include text-to-speech options.<br>Include audio options or having text read to students.<br>Having multiple levels of reading passages so students working below grade level can work towards their goal.<br>Provide “voice-first mode” and “light offline version” to support students with limited internet or shared devices. Let teachers adjust reading level recommendations. |
| **Teacher and Student Autonomy** | We want to make sure students can be successful even without the technology and that it is supporting them.<br>We want teachers to have access to their students work. | Sharing student responses and AI-feedback with educators.<br>Allowing teachers to override or supplement the AI-feedback.<br>Scaffolding the supports to lead towards independence with less prompts from AI.<br>Let teachers toggle among feedback modes (direct–guided–independent) and temporarily disable suggestions to observe students’ solo performance. |
| **Intellectual Property and Plagiarism** | We want to make sure students are not copying their work from an internet source and that it is truly their work. | Not allowing for copy/paste feature because we want to make sure students are typing and thinking of their ideas.<br>AI can provide sentence starters and we want to make it known what students came up with and where support was needed from AI.<br>Track typing time, paste actions, and tag AI-generated content level to help teachers assess originality. |
| **Emotional Well-being** | Things may be challenging for students and we do not want them to feel defeated. | Provide positive language like “Great job restating the question!”<br>And then giving the feedback so it is not only telling things they do wrong.<br>Have location for students to ask for help when they are struggling.<br>Create an emotion detection trigger: if students fail multiple times or click “I don’t know,” auto-switch to encouragement mode with step-by-step guides. |
| **Accountability and Responsibility** | Feedback systems need clear responsibility assignment for outputs and errors. | Each feedback entry should include model version, rubric used, timestamp, and edit history; teachers should have access to this review log.<br>Encourage each AI-generated response to include metadata tags for source traceability and clearer responsibility. |
| **Overselling and Hype** | The feedback is individualised but it does not replace teachers and what they are doing with students.<br>This is a tool to reinforce what they are learning in class.<br>Students still need to read and comprehend. Students still need to inference, it should not give the answer. | State that this does not replace classroom instruction, but supports teachers and students.<br>Do not use language that guarantees test score improvement.<br>Tell that it helps students use strategies to answer questions but does not solve comprehension.<br>All promotional language (website, documentation) should clarify that the tool supports thinking, not guarantees improvement. |
| **Ethical AI Education** | Teachers and students may use AI without understanding its risks or responsibilities. | At first login, display a visual “AI Use Instruction Sheet” for both teachers and students to clarify what AI can and cannot do, and how to report problems.<br>Recommend adding an “AI Ethics Self-Check” during onboarding to help students understand responsible use. |


### Societal and Ethical Implications of Generative AI in Education

The use of generative AI in education raises several ethical concerns, which require not only technical solutions but also educational reforms and stakeholder collaboration to ensure responsible, equitable, and human-centered implementation.

---

#### 1. Bias and Fairness
**Training Data Bias**: If the generative AI models are trained on biased data, they can perpetuate and amplify existing disparities in educational content, potentially leading to unfair treatment or discrimination.

**Personalization Bias**: Personalized learning systems powered by AI may inadvertently reinforce stereotypes or limit student opportunities based on assumptions about ability or identity.

   These risks are magnified in writing tasks, where linguistic expressions tied to culture or dialect may be misinterpreted as low proficiency. AI must be tuned to detect intent rather than surface form.

---

#### 2. Privacy and Data Security
**Student Data Protection**: The use of AI often involves large-scale data collection. Protecting students’ privacy requires minimizing data storage, anonymizing records, and securing transmission pathways.

**Informed Consent**: Families and students must understand what data is collected, how it is used, and have the right to opt in or out without losing access to educational support.

   Consent mechanisms should be age-appropriate and visually guided, particularly when AI is used in K–12 settings.

---

#### 3. Transparency and Explainability
**Opaque Decision-Making**: Complex AI models may make recommendations that are difficult to interpret, making it unclear why certain feedback or grades were issued.

   AI feedback should include “why this suggestion?” prompts linked to rubrics or model scoring rationales, helping students learn the reasoning behind each comment.

---

#### 4. Equity and Accessibility
**Technological Divide**: AI could worsen educational inequality if access depends on high-end hardware, internet speed, or exclusive subscriptions.

**Accessibility Challenges**: AI systems must accommodate students with diverse physical, cognitive, and linguistic needs.

   Equity efforts must also address cultural inclusivity: AI content should reflect global voices, not just Western norms or majority dialects.

---

#### 5. Teacher and Student Autonomy
**Loss of Control**: Heavy reliance on AI can shift authority away from educators and over-script students’ decisions.

   Tools should offer adjustable feedback levels, allowing teachers to scaffold or override suggestions and students to reflect on AI guidance before accepting it.

---

#### 6. Intellectual Property and Plagiarism
**Ownership of Content**: It must be clear who owns work co-produced by students and AI.

**Plagiarism Concerns**: Students may unintentionally plagiarize from AI outputs, or overuse sentence starters that diminish originality.

   Feedback systems should flag AI-influenced text and distinguish between inspiration, completion, and full generation.

---

#### 7. Emotional Well-being
**Emotional Impact**: If feedback is too frequent, negative, or impersonal, it may reduce motivation and increase stress.

   Emotional design in AI interfaces—such as tone of feedback and visible encouragement—should be as intentional as content accuracy.

---

#### 8. Accountability and Responsibility
**Attribution of Errors**: Who is responsible when AI-generated feedback is incorrect, harmful, or misleading?

   AI systems in education must include audit logs, allow human override, and empower teachers to document and report feedback mismatches.

---

#### 9. Overselling and Hype
**Exaggerated Claims**: Marketing AI as a solution to all educational problems risks disillusionment and distracts from pedagogy.

   Systems should be framed as assistive—not replacement—technologies, and pilot-tested before wide-scale rollout.

---

#### 10. Ethical AI Education
**Lack of Ethical Education**: Teachers and students often use AI without understanding its limitations, risks, or obligations.

   Basic AI literacy should be embedded into all levels of digital learning, including bias awareness, data rights, and feedback skepticism.

---



## Mitigation Strategies

**Training Data Bias**  
Implement diverse and representative training datasets, regularly audit data for biases, and use techniques like adversarial training to reduce bias.  

**Personalization Bias**  
Provide transparency in personalization algorithms, allow students to control and customize their learning experiences, and regularly evaluate and adjust personalization models.  

---

**Student Data Protection**  
Follow strict data protection regulations, anonymize and aggregate data when possible, and ensure that data storage and transmission adhere to robust security protocols.  

**Informed Consent**  
Clearly communicate data usage policies to students and parents, obtain explicit consent, and allow users to opt-out of certain data collection practices.  

---

**Opaque Decision-Making**  
Develop AI systems with explainability features, provide clear documentation on how decisions are made, and involve educators in the design process to enhance transparency.  

---

**Technological Divide**  
Promote initiatives to provide equal access to technology, such as subsidized devices or internet access, and ensure that AI tools are designed with varying levels of technology in mind.  

**Accessibility Challenges**  
Adhere to accessibility standards, conduct regular accessibility testing, and involve individuals with diverse abilities in the design and testing phases.  

---

**Loss of Control**  
Empower teachers to understand and modify AI recommendations, involve them in the decision-making process, and provide training on how to effectively integrate AI tools into their teaching methodologies.  

---

**Ownership of Content**  
Clearly define ownership rights in AI-generated content, educate students on intellectual property, and establish protocols for collaboration and attribution.  

**Plagiarism Concerns**  
Use plagiarism detection tools to identify AI-generated content, educate students on proper citation practices, and implement clear policies on plagiarism.  

---

**Emotional Impact**  
Augment AI tools with human emotional intelligence, prioritize human interactions for emotional support, and provide training for educators on recognizing and addressing emotional needs.  

---

**Attribution of Errors**  
Clearly define responsibility for AI system outcomes, establish protocols for handling errors, and involve human oversight in critical decision-making processes.  

---

**Exaggerated Claims**  
Encourage realistic expectations through transparent communication about the capabilities and limitations of AI tools in education.  

---

**Lack of Ethical Education**  
Integrate ethical AI education into the curriculum for both educators and students, covering topics such as bias mitigation, privacy, and responsible AI use.  




## References
1. Anwar, M., Mushtaq, N., Mubeen, A., & Iqbal, M. (2024). The Power of ZPD: Enhancing Teaching and Learning. Journal of Education and Social Studies, 5, 396-405.
1. Clark, J.M., & Paivio, A. (1991). Dual coding theory and education. Educational Psychology Review, 3(3).
1. Hattie, J., & Timperley, H. (2007). The Power of Feedback. Review of Educational Research, 77(1), 81-112.
1. Martinez, M.E. (2010). Learning and Cognition: The Design of the Mind. Merrill.
1. Paivio, A. (1986). Mental Representations: A Dual-Coding Approach. Oxford University Press.
1. Reiser, B.J., & Tabak, I. (2014). Scaffolding. Cambridge Handbook of Learning Sciences, 2nd Ed.
1. Sweller, J. (1988). Cognitive load during problem solving. Cognitive Science, 12(2), 257-285.
1. Winne, P.H., & Azevedo, R. (2014). Metacognition. Cambridge Handbook of Learning Sciences.
