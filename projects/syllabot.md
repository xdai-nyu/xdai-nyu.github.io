## Syllabot 
### Learning to read through gamified embodied storytelling
### Project Members: 
Melody Hammer, Cass Scheirer, Shengkai (Kai) Xu
Project outline: https://docs.google.com/document/d/1vrhUMmzpPFNJyKwj4uYAjJyPBs0kYPaRa17JunjWJXA/edit?tab=t.0
### Target Learning Audience: 
Pre-K and elementary school students 
### Modalities: 
A combination of screen-based interactions and physical engagement with a robotic toy.

### Identified Learner Needs
Young learners (ages 3-10) often struggle with attention, phonics, word recognition, and comprehension, requiring interactive and multimodal reinforcement from an instructive body (Ehri, 2005). Traditional reading instruction lacks personalization and fails to address the diverse needs of early learners, especially those with short attention spans or learning difficulties. Research in cognitive science suggests that multimodal learning technologies — combining visual, auditory, and kinesthetic interactions — may enhance retention and comprehension (Mayer, 2021). Indeed, interactive multimedia approaches to literacy education, such as games (Franceschini et al., 2015; Gorgen et al., 2020), apps (Chuang et al., 2023) and augmented reality books (Şimşek et al., 2023) have been developed in response. These tools have shown to enhance the reading experience and improve learning, especially for students with learning disabilities. 

However, these tools also have multiple limitations. Many of them feature pre-defined stories and require the use of screens, limiting the meaningfulness of the reading content and the potential for embodied cognition to reinforce the representation of literacy concepts. Further, parents remain skeptical of digital applications as a replacement for traditional books (Kucirkova et al., 2020; Azir et al., 2022). Finally, many of these applications still require or encourage parental involvement, which can be hard on busy parents and parents of slow readers (Mudzielwana, 2014; Melody’s personal experience). Few learning designers have explored how AI-enhanced social robots have the potential to target all of these issues by personalizing, physicalizing, and autonomizing the process of learning to read. 

### Rationale for AI Assistance
Our project leverages AI-driven personalization, interactive storytelling, and embodied cognition to create a more engaging and effective reading experience. A social robot with a visual interface will collaborate with the learner to develop a custom gamified storytelling experience in which the robot prompts the learner to read instructions for physical actions to be acted out related to the story. Real-time assessment, gradual visual hints, collaboration, and physical movement facilitated by the robotic toy will support the learner in decoding words, improving fluency, and reinforcing memory while also engaging their creative and physical senses. These approaches align with constructivist learning theories, emphasizing active participation and meaningful interaction in literacy development.

### Problem Statement
Young learners (ages 3-10) often struggle with attention, phonics, and comprehension, requiring interactive, multimodal support. Traditional reading instruction lacks personalization, making literacy development challenging. This project introduces an AI-driven robotic reading companion that adapts to each child’s progress using speech recognition, eye tracking, and embodied cognition. By integrating phonics-based hints, visual aids, and physical engagement, it enhances fluency, comprehension, and retention, bridging a critical gap in early literacy education.

## Identified Learner needs
### 1. Personalized Reading Support
_“Young learners vary in their reading abilities, attention spans, and learning styles, yet traditional instruction often provides a one-size-fits-all approach. Personalized feedback, phonics-based hints, and real-time assessment help children progress at their own pace, reinforcing prior knowledge while addressing individual learning gaps.”_

### 2. Multimodal Engagement for Retention
_“Many children struggle with focus and comprehension when learning through static or text-based instruction. By integrating visual aids, auditory cues, and interactive storytelling, the system enhances engagement and supports decoding, fluency, and memory retention through germane cognition.”_

### 3. Embodied Cognition for Active Learning
_“Young children benefit from physical interaction as part of the learning process, particularly those with short attention spans or sensory learning preferences. Encouraging movement through embodied cognition—such as acting out stories—reinforces literacy skills by linking learning to muscle memory and increasing sustained engagement.”_

## Moodboards
<img width="877" alt="Moodboard 1" src="https://github.com/user-attachments/assets/456b2d24-952c-4385-a93e-af460ac14f55" />

<img width="877" alt="Moodboard 2" src="https://github.com/user-attachments/assets/0a8aa845-769d-44d5-b928-c57f9afb7632" />


## Secondary Research
### Literature Review
**Build Your Own Robot Friend: An Open-Source Learning Module for Accessible and Engaging AI Education**
Used an open source 3D printed robot structure and designed an AI/robotics learning module that focused on building that robot from scratch. The researchers created their own fabric “clothing” that the users could use to customize the look of their robot — however this clothing did not have any relevance to the user’s identity and there were limited options. They found that the learners felt like the workshop helped them learn and be interested more about robotics and AI, but learning was self-reported as it was only a usability study. They did not collect data on how the choice of clothing affected the learning experience.

Shi, Z., O'Connell, A., Li, Z., Liu, S., Ayissi, J., Hoffman, G., Soleymani, M., & Matarić, M. J. (2024). Build your own robot friend: An open-source learning module for accessible and engaging AI education. arXiv. https://doi.org/10.48550/arXiv.2402.01647

**Child Perception of Humanoid Robot Appearance and Behavior**
Researchers asked 578 children to evaluate images and videos of different physical designs of robots. These designs ranged on a scale matching the uncanny valley graph, from mechanical to zoomorphic to complete anthropomorphism. Results show that zoomorphic designs are the most interesting/engaging to children both socially and physically. They also found that the curve of the ratings of dynamic robots is much flatter than the uncanny valley graph predicts, meaning that anthropomorphic movement can mitigate the negative effects of uncanny visual designs.
Tung, F.-W. (2016). Child perception of humanoid robot appearance and behavior. International Journal of Humanoid Robotics, 13(01), 1550036.

**Impacting the Perception of Socially Assistive Robots- Evaluating the effect of Visual Qualities among Children**
Researchers analyzed 20 socially assistive robots into 5 categories related to their design features and asked children to assess each robot according to these features. They found that design features such as edge type and color had a significant impact on the children’s perception of robot gender and vibe.

Liberman-Pincu, O., Oron-Gilad, T., & Parmet, Y. (2021). Impacting the perception of socially assistive robots: Evaluating the effect of visual qualities among children. In 2021 30th IEEE International Conference on Robot & Human Interactive Communication (RO-MAN) (pp. 1186–1192). IEEE. https://doi.org/10.1109/RO-MAN50785.2021.9515458

**Social Robots as Creativity Eliciting Agents**
Researcher explores how social robots can encourage creativity in children through interactive and collaborative activities. The authors designed experiments where social robots provided feedback and prompts to stimulate creative thinking, demonstrating that children responded positively and showed increased creative output. The study highlights the potential for social robots to serve as engaging and supportive partners in creative learning environments.

Ali, S., Devasia, N., Park, H. W., & Breazeal, C. (2021). Social robots as creativity eliciting agents. Frontiers in Robotics and AI, 8, Article 673730. https://doi.org/10.3389/frobt.2021.673730


### Commercial Solution Research
**LOVOT Robot Cafe (GROOVE X)**
Designed for emotional bonding, LOVOT is a small, soft robot with a digital face that displays emotions. It moves, reacts to touch, and recognizes its owner.

<img width="447" alt="Lovot2" src="https://github.com/user-attachments/assets/9d1c45a8-b228-49c9-bb67-12376bac7800" />

**Resource links**
Groove X

SoraNews

YouTube


**Technical Features:**
Over 50 censors, including multiple pressure sensors

• 360 camera view

• Thermal camera

• Two microphones

• Two wheels with trackball system

• Navigation to avoid obstacles

**Cost:**
$3,000-$5,000

**LOVOT AI Capabilities**
**Facial Recognition** – uses its camera and AI to recognize different people and develop stronger bonds with those who interact with it the most.

<img width="445" alt="Lovot1" src="https://github.com/user-attachments/assets/d4700a47-b8ef-48e6-9bab-21d9a800b65b" />


**Emotional Learning** – It adapts its behavior based on how it is treated, remembering past interactions and responding accordingly.

**Customizable Reactions** – LOVOT learns what kinds of interactions you prefer (e.g., hugs, pats, following you around) and adjusts its responses to make engagement more personal.

**Routine Adaptation** – It recognizes daily routines and might become more active when you usually play with it.
Voice & Name Recognition – It can remember and respond to its name and certain commands over time.



## Research Goals and Methodology
### Goal
The survey data we collected focused on understanding the reading habits, challenges, and toy interaction preferences of children between the ages of 3 and 10. 

### Key areas of focus
• Background information

• Reading habits

• Reading challenges

• Attitudes on AI

• Toy design preferences

• Physical embodiment

### Methodolgy
Our methodology is structured around a mixed-methods approach that combines quantitative and qualitative analysis to understand how children engage with reading and interactive toys, as well as to inform the design of an AI reading companion.

**Target Audience:** Parents of children 3-10

**Sample Size:** 6 parents, 10 children

**Voluntary Participation:** Participants were self-selected, meaning they opted to respond based on their interest.

**Research method:** 30 questions, survey-based
Link to survey: https://docs.google.com/forms/d/13GSBiD8pYiUozUOrHxml1rVSytgp6z4pku_LKZafF68/edit

## Key Findings & Insights
Parent survey results

Link to survey: https://docs.google.com/forms/d/13GSBiD8pYiUozUOrHxml1rVSytgp6z4pku_LKZafF68/edit#responses

**Common Reading Challenges**
The biggest challenge for children learning to read is blending sounds into words (83.3%).
50% of children struggle with recognizing letters and sounds.
Other difficulties include reading fluency (33.3%) and understanding content (33.3%).
<img width="748" alt="Question3" src="https://github.com/user-attachments/assets/3a35b3ec-c06a-451f-967c-31f8f3b0eff4" />

**Use of Reading Apps and Digital Tools**
50% of parents do not currently use reading apps but are open to trying them.
16.7% of parents regularly use reading apps, while 16.7% use them occasionally.
Some parents prefer traditional learning methods or use audiobooks at bedtime.
<img width="757" alt="Question7" src="https://github.com/user-attachments/assets/6530c678-b6db-4b24-9992-dab065a4289c" />

**Parent Attitude Toward AI Technology in Learning**
66.7% of parents are neutral about AI technology in learning.
33.3% have a positive attitude toward AI in learning.
No parents expressed a negative attitude toward AI-based learning tools.

**Potential Impact of a Companion Robot**
50% of parents believe a reading companion robot would help improve reading skills.
33.3% are uncertain, while 16.7% doubt its effectiveness.

**Concerns About Using a Robot-Based Learning Tool**
The biggest concern (66.7%) is privacy and data security.
33.3% prefer human interaction over AI.
16.7% worry their child might lose interest quickly.
<img width="752" alt="Question12" src="https://github.com/user-attachments/assets/0634061b-7a35-403d-906c-171a97b88755" />

**Preferred AI Features for Reading Growth**
100% of parents want the AI to assess their child's reading level.
83.3% value adaptive content based on interests and reading level.
66.7% want the AI to encourage interactive storytelling and physical engagement.
<img width="756" alt="Question13" src="https://github.com/user-attachments/assets/c17d486a-b16a-4375-b7f9-b811abd1736e" />

**Favorite Types of Tangible Toys**
83.3% of children enjoy puzzles and board games.
66.7% prefer stuffed animals, building toys, and electronic toys.
Sports and arts & crafts are also popular with 50% engagement.
<img width="757" alt="Question14" src="https://github.com/user-attachments/assets/6c2968ca-b5b0-44e6-ad02-e22c4847d2fb" />

**Engaging Features in Toys**
66.7% of parents say moveable parts and personalization are the most engaging features.
50% value sounds and physical activity.
16.7% noted lights, storytelling, and color preferences as important.
<img width="751" alt="Question16" src="https://github.com/user-attachments/assets/1d55f970-3868-42d6-b15c-d038fe63f424" />
   
**Importance of Toys in Child Development**
100% of parents say toys support creativity and imagination.
83.3% believe toys serve as entertainment.
50% say toys help develop motor skills.
<img width="757" alt="Question22" src="https://github.com/user-attachments/assets/2a1dfa48-b319-4f80-925f-91c0d164a703" />

**Physical Actions During Storytelling**
60% of children engage with stories through role-playing and drawing.
40% use gestures and expressive movements to enhance their storytelling experience.
<img width="756" alt="Question26" src="https://github.com/user-attachments/assets/56343371-15d7-43a4-82b8-32c947c9de81" />


## Proto personas
Mel to fill out (post 3/10)

## Storyboarding & Prototyping
<img width="1496" alt="Melody's mood board" src="https://github.com/user-attachments/assets/d46b8492-a583-41c9-a95b-6870774395b1" />


AI Prototype (Kai)

https://wokwi.com/projects/425032280169786369

Robotic Prototype/Materials Audit (Cass)

<img width="404" alt="Example Syllabot body" src="https://github.com/user-attachments/assets/560938b2-fff0-4f05-96f1-48dfecd44094" />
<img width="851" alt="Different interaction flows" src="https://github.com/user-attachments/assets/f1426c34-d06f-4e9d-9a0c-a835707f8431" />



## Midterm reflection

Melody: I'm glad we gathered feedback from parents before starting the design phase of our project. I'm curious to see how all the secondary research and perspectives come together as we develop the prototype for the trial with participating parents and children.

Cass:

Kai: 







